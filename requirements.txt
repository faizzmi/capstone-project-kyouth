# 1. Create customized calculated columns (example: total price = quantity * unit price)
df['total_price'] = df['quantity'] * df['unit_price']

# 2. Standardize formatting for date-time fields
df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')

# 3. Standardize categorical variables (example: lowercase and strip spaces)
df['category'] = df['category'].str.lower().str.strip()

# 4. Ensure consistent data types across columns
df['customer_id'] = df['customer_id'].astype(str)
df['quantity'] = df['quantity'].astype(int)
df['unit_price'] = df['unit_price'].astype(float)

# 5. Perform range checks to validate data accuracy
# Example: quantity should be > 0
invalid_quantity = df[df['quantity'] <= 0]
print("Invalid quantity rows:", invalid_quantity)

# Example: total_price should not exceed an unrealistic threshold
print(df[df['total_price'] > 100000])


# 1. Merge datasets correctly using appropriate join type
# Example: join orders with customers on 'customer_id'
merged_df = pd.merge(orders_df, customers_df, on='customer_id', how='inner')

# 2. Manage missing values that appeared after merging
print(merged_df.isnull().sum())   # check new missing values

# Example: fill missing values after join
merged_df['address'] = merged_df['address'].fillna("Unknown")        # categorical
merged_df['total_spent'] = merged_df['total_spent'].fillna(0)        # numeric

# Optional: if too many missing rows, consider dropping them
merged_df = merged_df.dropna(subset=['customer_id'])

# 1. Broad descriptive analysis to summarise the dataset
print(df.describe(include='all'))
print(df.info())

# 2. Apply filters to focus analysis on relevant subsets
high_value_orders = df[df['total_price'] > 1000]
recent_orders = df[df['order_date'] >= "2024-01-01"]

# 3. Use groupby() for segmented aggregation/analysis
# Example: average total price per category
avg_price_per_category = df.groupby('category')['total_price'].mean()
print(avg_price_per_category)

# Example: total quantity per customer
total_qty_per_customer = df.groupby('customer_id')['quantity'].sum()
print(total_qty_per_customer)

# 4. Interpret key patterns, trends, or outliers
# Example: identify top 5 customers by spending
top_customers = df.groupby('customer_id')['total_price'].sum().nlargest(5)
print("Top 5 customers by total spending:\n", top_customers)

# Example: detect unusually high order values
outliers = df[df['total_price'] > df['total_price'].quantile(0.99)]
print("Potential outlier orders:\n", outliers)
